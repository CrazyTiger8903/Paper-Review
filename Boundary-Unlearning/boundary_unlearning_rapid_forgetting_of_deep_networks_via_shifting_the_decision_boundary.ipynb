{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOf8TY2TZA0cpkWY/2zudXg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CrazyTiger8903/Paper-Review/blob/main/Boundary-Unlearning/boundary_unlearning_rapid_forgetting_of_deep_networks_via_shifting_the_decision_boundary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# boundary unlearning: rapid forgetting of deep networks via shifting the decision boundary(CVPR 2023)"
      ],
      "metadata": {
        "id": "QHmQ3CsHFzKm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.Introduction\n",
        "\n",
        "---\n",
        "\n",
        "- Machine Unlearing : 머신러닝 모델이 일부 학습 데이터를 잊도록 하거나 그 계통을 삭제시키는 것을 의미\n",
        "\n",
        "- 왜 필요한가?\n",
        "  1.   \"the right to be forgotten\" : 개인 데이터의 삭제를 요청하면 기업은 반드시 삭제해야한다(GDPR)\n",
        "  2.   머신러닝 모델에 유용\n",
        "    -   데이터 중독 공격(학습 데이터를 조작하여 모델의 성능 저하 또는 잘못 판단하도록 하는 공격)\n",
        "    -   시간이 지나 유효하지 않은 학습 데이터\n",
        "    -   학습 후 학습 데이터가 오류로 판단\n",
        "\n",
        "- 초기연구\n",
        "  1.   처음 부터 retraining -> 시간 오래 걸림\n",
        "  2.   모델 파라미터를 scrubbing(정리)하여 forgetting data(삭제 대상 데이터)의 영향을 제거 -> 파라미터 space 차원이 너무 크기 때문에 cost가 비싸다.\n",
        "\n",
        "- Retrained Model의 결정 공간 특징\n",
        "  1.   forgetting samples가 모델의 결정 공간 전체에 퍼져 있다. 즉 forgetting samples의 결정 경계가 깨졌다.\n",
        "  2.   대부분의 forgetting samples는 다른 클러스터의 경계로 이동\n",
        "    - closest-to-boundary criterion : 결정 공간의 클러스터 경계에 있는 샘플은 예측 시 높은 불확실성을 보일 가능성이 크다.\n",
        "  3. 이러한 특징은 machine unlearning의 2가지 목표에 자연스럽게 부합한다.\n",
        "    - Utility guarantee(유용성 보장) : forgetting data(삭제 대상 데이터)에 대해서는 일반화 성능이 낮아야 하며, 나머지 데이터에 대한 예측 성능은 유지되어야 한다.\n",
        "    - privacy guarantee : unlearned 모델은 삭제 대상 데이터의 정보를 유출해서는 안된다.\n",
        "    - 이 논문에서는 forgetting data의 경계만 파괴하고, 나머지는 유지함으로써 Utility guarantee를 달성하고, forgetting data를 다른 클러스터의 경계로 밀어냄으로써 privacy guarantee를 달성한다.\n",
        "\n",
        "  <img src='https://drive.google.com/uc?id=1KuoVnQL0p0YejkocQIq172TBEVomaasD'/>\n",
        "\n",
        "- Boundary Unlearning\n",
        "  1. 결정 공간에서 결정 경계를 이동시켜 빠르고 효과적으로 모델에서 삭제 대상 클래스를 잊게 하는 방법인 \"Boundary Unlearning\" 제안\n",
        "  2. Boundary Shrink : forgetting class(삭제 대상 클래스)를 다른 클래스로 분할하여 결정 경계를 파괴.\n",
        "  3. Boundary Expanding : forgetting 데이터를 shadow class로 매핑 후 이 클래스를 제거하여 활성화를 분산.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hQdo0cLZnbF3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Related Work\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "wVRwqnKGxGbV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Preliminaries and Notation\n",
        "---\n",
        "1. $D$ : training dataset. 전체 학습 데이터셋으로, 입력데이터 x와 클래스 레이블 y로 구성\n",
        "\n",
        "2. $D_{f} $ : Forgetting Data. 삭제해야 할 데이터의 부분 집합. 주로 특정 클래스의 모든 샘플로 구성됨. (예를 들면, dog 클래스 전체를 삭제.)\n",
        "\n",
        "3. $D_{r} $ :  Remaining Training Data. $D_{f} $(삭제 대상 데이터)를 제외한 나머지 데이터. 즉 유지하려는 정보들\n",
        "\n",
        "4. $f_{ w_{0} } $ : 학습데이터 D에 대해 학습된 Original 모델. w0로 파라미터화 되어 있다. $f_{ w_{0} }(x) $는 학습된 모델이 x에 대해 출력하는 로짓을 나타낸다.\n",
        "\n",
        "5. $f_{w*} $ : retrained 모델($D_{r} $로 다시 학습된 모델) 최적의 데이터 삭제 모델로 간주.\n",
        "\n",
        "6. $f_{w'}$ : 데이터 삭제를 수행한 후 얻어진 모델.\n",
        "\n",
        "- 최종 목표 : fw'(데이터 삭제 후 얻어진 모델)이 fw*(재학습 시킨 모델)와 최대한 유사하게 만드는 것.\n",
        "\n",
        "7. decision boundary(결정경계) : 입력 x가 클래스 i와 j 중 어느 클래스로 분류될지 결정하는 경계. 두 클래스의 확률이 동일해지는 지점"
      ],
      "metadata": {
        "id": "YmxaVZBLxOe0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Proposed Methods\n",
        "---\n",
        "### 4.1. Boundary Shrink\n",
        "- Random Labeling\n",
        "  - 랜덤하게 라벨링된 forgetting 데이터를 사용해 파인튜닝을 진행하는 방법\n",
        "  - 가장 직관적인 방법이지만, 나머지 클래스의 경계도 랜덤하게 이동 시켜 나머지 데이터에 대한 모델 utility저하\n",
        "\n",
        "- Retrained 모델의 결정 경계에서 확인할 수 있듯, 대부분의 forgetting 샘플은 랜덤한 클래스가 아닌 특정 클래스들로 예측. 즉, 특징 공간에서 forgetting 샘플과 다른 클래스의 샘플들 간의 유사성 발견이 중요하다.\n",
        "\n",
        "- 제안\n",
        "  - 적대적 공격(adversarial attacks)을 기반으로 이웃 탐색 방법을 제안\n",
        "    - 가장 가까운 결정 경계를 넘어 적대적 예제(adversarial examples)를 생성할 수 있는 방법\n",
        "    - forgetting 샘플의 결정 경계를 이동시키는 방향을 알려주며, 원래 모델에서 cross samples(잘못된 예측)를 예측함으로써 가장 가까우면서도 잘못된 라벨을 얻을 수 있다.\n",
        "  - cross samples의 라벨을 해당하는 forgetting 샘플에 할당\n",
        "  - 재할당 된 모든 샘플로 원래 모델을 파인튜닝하면, forgetting 클래스의 경계가 정확한 방향으로 축소될 수 있다.\n",
        "\n",
        "1. Original 모델 학습\n",
        "  - $ w_0 = \\arg\\min_w \\sum_{(x_i, y_i) \\in D} L(x_i, y_i, w) $\n",
        "  - $w_0$(original 모델의 가중치)\n",
        "  - D(전체 데이터세트)에 대해 손실 L을 최소화하는 최적의 파라미터를 나타냄\n",
        "2. 이웃검색방법을 사용하여 가장 가까우면서 잘못된 레이블 찾기\n",
        "  - $x'_f = x_f + \\epsilon \\cdot \\text{sign} \\left( \\nabla_{x_f} L(x_f, y, w_0) \\right)$\n",
        "  - original 모델의 손실 함수의 $ x_{f}$에 대한 gradient 계산\n",
        "  - sign을 통해 gradient의 부호를 취해 방향을 결정. 즉 크기는 제외하고 방향성 만을 추출한다.\n",
        "  - gradient의 방향성에 일정한 크기의 노이즈 크기 $\\epsilon$(엡실론)을 추가\n",
        "  - 이를 통해 $ x_{f}$의 결정 경계를 넘도록 노이즈를 추가한다. - 적대적 공격과 유사(PGD Attack)\n",
        "  - $y_{nbi} \\leftarrow \\text{softmax} \\left( f_{w_0}(x'_f) \\right)$\n",
        "  - $x'_f$(cross sample)에 대해 original 모델 $f_{w_0}$를 사용해 가장 가깝지만 잘못된 레이블 $y_{nbi}$를 예측\n",
        "3. fine-tunning\n",
        "  - $w' = \\arg \\min_w \\sum_{(x_i, y_{nbi}) \\in D_f} L(x_i, y_{nbi}, w_0)$\n",
        "  - forgetting 클래스의 boundary shrink를 위해 재할당된 샘플로 original 모델을 파인 튜닝. 이를 통해 최적의 파라미터 w'을 획득\n",
        "\n",
        "- 이를 통해 모델이 학습한 데이터 간의 관계를 최대한 보존하면서 결정 경계를 조정할 수 있게 된다.\n",
        "\n",
        "### 4.2. Boundary Expanding\n",
        "\n"
      ],
      "metadata": {
        "id": "pdp77eYVxSyY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Performance Evaluation\n",
        "\n",
        "---\n",
        "1. Utility Guarantee\n",
        "  - 모델 정확도를 통해 평가\n",
        "  - 다른 베이스라인 모델과 비교하였을때, Boundary Shrink는 Df에 대한 정확도를 크게 줄이면서, Dr에 대한 정확도를 최소한으로 감소시킨다.\n",
        "  - Boundary Expanding은 Df에 대한 정확도가 조금 더 높지만, 성능과 시간 사이의 균형을 맞춘 빠른 대안으로 사용 가능하다.\n",
        "\n",
        "  <img src='https://drive.google.com/uc?id=1VOQwfeJkygY4VMXLg5UvJ7YypsJ966Yc'/>\n",
        "\n",
        "2. Privacy Guarantee\n",
        "  - ASR(Attack Success Rate)를 통해 평가\n",
        "  - ASR이 100%에 가까울수록 Df에 대한 정보가 덜 제거되었음을 의미\n",
        "  - ASR이 0%에 가까울수록 Streisand 효과를 나타낼 수 있음(Df의 모든 샘플이 하나의 클래스로 예측되어, 삭제 데이터에 대한 더 많은 정보를 제공할 가능성을 의미)\n",
        "  - Finetune의 경우 높은 Utility 성능을 보였지만, Privacy 성능의 경우 낮은 성능을 보임(삭제 데이터에 대한 정보를 거의 제거하지 못했음)\n",
        "  - Boundary Shrink와 Boundary Expanding 방법 모두 준수한 성능을 보임\n",
        "\n",
        "   <img src='https://drive.google.com/uc?id=18rlJDnCK9U9uAnrgLPMa3uH-JXBSaXjE'/>\n",
        "\n",
        "3. Computational Complexity\n",
        "  - Retrain 대비 많은 시간 단축\n",
        "  - Boundary Shrink는 교차 샘플 생성(cross-sample generation) 과정 때문에 Boundary Expanding보다 약간 더 많은 시간이 소요\n",
        "\n",
        "  <img src='https://drive.google.com/uc?id=1JCzMtLRl9GYfdGpXYOa5T-aSkCt0pRck'/>\n",
        "\n",
        "\n",
        "4. Attention Map\n",
        "  - Retrain 모델의 attention map을 통해 unlearning되었을 때 모델이 얼굴 영역에 집중하지 않는 다는 것을 확인할 수 있다.\n",
        "  - Boundary Shrink로 unlearning된 경우 모델의 주위를 오직 배경에만 집중시키도록 한 것을 확인\n",
        "  - Boundary Expanding의 경우 주위를 완전히 배경으로 전환시키지 못했지만, 여전히 얼굴 외부 영역으로 집중을 전환시킨 것을 확인\n",
        "\n",
        "  <img src='https://drive.google.com/uc?id=1C5Nz__kfF9uu9UrdQkiw9N0v6OarI9ng'/>\n",
        "\n",
        "5. Visualization of Decision Space\n",
        "  - Boundary Shrink를 적용한 후 가장 가까운 클래스로 예측되는 것을 확인\n",
        "  - Retrain 모델처럼 클러스터가 완전히 퍼지지는 않았지만, forgetting data의 결정 공간이 근처의 클래스에 의해 나눠지는 것을 확인할 수 있다.\n",
        "  - Boundary Expanding의 경우 forgetting data의 클러스터가 중심에서 밀려나는 것을 확인할 수 있다.\n",
        "\n",
        "  <img src='https://drive.google.com/uc?id=1M5hdFb0NjhRjBIjf21NGTrmitm3haGDe'/>\n",
        "\n",
        "6. Distribution of the Entropy of Model Output\n",
        "  - 엔트로피가 낮음 : 데이터를 예측할 때 더 확신을 갖고 예측함을 의미\n",
        "  - Retrained Model은 Df의 엔트로피 수치가 크게 증가하는 것을 확인할 수 있다.\n",
        "  - Boundary Shrink와 Expanding의 결과 역시 Retrained의 결과와 유사한 것을 확인할 수 있다.\n",
        "  - Random Labels의 경우 Df의 엔트로피 수치가 상당히 큰 것을 볼 수 있는데, 이는 Retrained model과 큰 차이를 보인다.\n",
        "\n",
        "  <img src='https://drive.google.com/uc?id=1VnyEitYD_dFq9ZcuTtdVGT00PB5aQ1U1'/>"
      ],
      "metadata": {
        "id": "81_JJpKWxTc8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "\n",
        "---\n",
        "- 결정 경계를 이동시켜 학습된 DNN에서 특정 클래스 전체의 정보를 제거하는 최초의 머신 언러닝 기법인 Boundary Unlearning을 제안\n",
        "- 과도한 계산 자원을 소모하지 않으며, 기존 학습 파이프라인에 개입하지 않음\n",
        "- Utility와 Privacy 보장 모두에서 빠르고 효율적인 망각 성능을 보임\n"
      ],
      "metadata": {
        "id": "ICcUkk3hwwuL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 코드 구현"
      ],
      "metadata": {
        "id": "v78q98tfzwqD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Original & Retrain 모델 만들기\n",
        "1-1. pytorch 라이브러리를 이용하여 ResNet18 모델을 구현하고 CIFAR-10 데이터셋을 학습한 'Original'모델을 만들고 정확도 등을 평가하세요.\n",
        "\n",
        "1-2. 10개 클래스 중 한 개의 클래스를 선택해 이를 제외한 나머지 9개 클래스의 데이터로 학습한 'Retrain'모델을 만들고 각 데이터에 대한 정확도 등을 평가하세요 (train forgetset, train remainset, test forgetset, test remainset...)\n",
        "\n",
        "\n",
        "- 1-1 Result\n",
        "  - Train Remainset Accuracy (others): 99.99%\n",
        "  - Train Forgetset Accuracy (deer): 100.00%\n",
        "  - Test Remainset Accuracy (others): 83.08%\n",
        "  - Test Forgetset Accuracy (deer): 82.50%\n",
        "\n",
        "    <img src='https://drive.google.com/uc?id=1I5Eud6OMcq1G7I6mbq4lIRl3TM_py7lH' width='450' height='450' />\n",
        "\n",
        "- 1-2 Result\n",
        "  - Train Remainset Accuracy (others): 99.99%\n",
        "  - Train Forgetset Accuracy (deer): 0.00%\n",
        "  - Test Remainset Accuracy (others): 83.93%\n",
        "  - Test Forgetset Accuracy (deer): 0.00%\n",
        "\n",
        "    <img src='https://drive.google.com/uc?id=19dLiQm8hgs5sPy3JRgKkIlfSs53xHXQZ' width='450' height='450' />"
      ],
      "metadata": {
        "id": "7TNAqX432DwN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "boundary unlearning: rapid forgetting of deep networks via shifting the decision boundary(CVPR 2023)\n",
        "\n",
        "Original 모델(Cifar10 데이터세트로 훈련된 모델) 학습 및 시각화 코드\n",
        "Train Remainset Accuracy (others): 99.99%\n",
        "Train Forgetset Accuracy (deer): 100.00%\n",
        "Test Remainset Accuracy (others): 83.08%\n",
        "Test Forgetset Accuracy (deer): 82.50%\n",
        "\n",
        "to do : 모듈화\n",
        "\"\"\"\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.models import resnet18\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import random\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "save_dir = \"./Result\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# 데이터셋 분리 함수\n",
        "def split_datasets(dataset, target_class):\n",
        "    forget_indices = [i for i, (_, label) in enumerate(dataset) if label == target_class]\n",
        "    remain_indices = [i for i, (_, label) in enumerate(dataset) if label != target_class]\n",
        "    return Subset(dataset, forget_indices), Subset(dataset, remain_indices)\n",
        "\n",
        "# 삭제 대상 클래스 - deer(4)\n",
        "target_class = 4\n",
        "\n",
        "train_forgetset, train_remainset = split_datasets(train_dataset, target_class)\n",
        "test_forgetset, test_remainset = split_datasets(test_dataset, target_class)\n",
        "\n",
        "train_forget_loader = DataLoader(train_forgetset, batch_size=64, shuffle=True)\n",
        "train_remain_loader = DataLoader(train_remainset, batch_size=64, shuffle=True)\n",
        "test_forget_loader = DataLoader(test_forgetset, batch_size=64, shuffle=False)\n",
        "test_remain_loader = DataLoader(test_remainset, batch_size=64, shuffle=False)\n",
        "\n",
        "# ResNet18 모델 초기화\n",
        "def create_model(num_classes=10):\n",
        "    model = resnet18(pretrained=True)\n",
        "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "    return model\n",
        "\n",
        "# 학습 함수\n",
        "def train_model(model, dataloader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    for inputs, labels in dataloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# 평가 함수\n",
        "def evaluate_model(model, dataloader, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return correct / total\n",
        "\n",
        "# Original 모델 학습\n",
        "best_accuracy = 0.0\n",
        "epoch = 50\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "original_model = create_model(num_classes=10).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(original_model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# 학습\n",
        "for i in range(epoch):\n",
        "    train_model(original_model, train_loader, criterion, optimizer, device)\n",
        "    accuracy = evaluate_model(original_model, test_loader, device)\n",
        "    print(f\"Epoch {i+1}, Test Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "    # 최고 정확도 갱신 시\n",
        "    if accuracy > best_accuracy:\n",
        "        best_accuracy = accuracy\n",
        "\n",
        "        # 최고 성능 모델 가중치 저장\n",
        "        best_weight_path = os.path.join(save_dir, \"Org_Model.pth\")\n",
        "        torch.save(original_model.state_dict(), best_weight_path)\n",
        "        print(f\"New best accuracy: {accuracy * 100:.2f}% - Weights saved at {best_weight_path}\")\n",
        "\n",
        "\n",
        "print(\"Training complete. Best weights saved as 'best_model.pth'\")\n",
        "\n",
        "\n",
        "# TSNE 시각화 함수\n",
        "def plot_tsne(model, remain_loader, forget_loader, device, title, classes, save_path):\n",
        "    model.eval()  # 모델을 평가 모드로 전환\n",
        "    features = []  # 추출된 특징 저장 리스트\n",
        "    predictions = []  # 예측 클래스 저장 리스트\n",
        "    dataset_type = []  # \"Remain\" 또는 \"Forget\" 구분 저장 리스트\n",
        "\n",
        "    # Remainset 데이터에서 특징 및 예측 결과 추출\n",
        "    with torch.no_grad():\n",
        "        for inputs, _ in remain_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            outputs = model(inputs)\n",
        "            features.append(outputs.cpu().numpy())  # 모델 출력 특징 저장\n",
        "            predictions.append(torch.argmax(outputs, dim=1).cpu().numpy())  # 예측 결과 저장\n",
        "            dataset_type.extend([\"Remain\"] * inputs.size(0))  # Remainset 데이터 구분 추가\n",
        "\n",
        "    # Forgetset 데이터에서 특징 및 예측 결과 추출\n",
        "    with torch.no_grad():\n",
        "        for inputs, _ in forget_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            outputs = model(inputs)\n",
        "            features.append(outputs.cpu().numpy())  # 모델 출력 특징 저장\n",
        "            predictions.append(torch.argmax(outputs, dim=1).cpu().numpy())  # 예측 결과 저장\n",
        "            dataset_type.extend([\"Forget\"] * inputs.size(0))  # Forgetset 데이터 구분 추가\n",
        "\n",
        "    # 데이터를 합침\n",
        "    features = np.concatenate(features, axis=0)\n",
        "    predictions = np.concatenate(predictions, axis=0)\n",
        "    dataset_type = np.array(dataset_type)\n",
        "\n",
        "    # TSNE로 차원 축소\n",
        "    # tsne = TSNE(n_components=2, perplexity=40, learning_rate=300, n_iter=3000, random_state=42)\n",
        "    tsne = TSNE(n_components=2, perplexity=50, learning_rate=500, n_iter=4000, random_state=42)\n",
        "    reduced_features = tsne.fit_transform(features)\n",
        "\n",
        "    # 시각화\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    colors = plt.cm.Paired(np.linspace(0, 1, len(classes)))\n",
        "\n",
        "    # Remainset 데이터 시각화\n",
        "    remain_features = reduced_features[dataset_type == \"Remain\"]\n",
        "    remain_predictions = predictions[dataset_type == \"Remain\"]\n",
        "    for i, class_name in enumerate(classes):\n",
        "        indices_remain = remain_predictions == i\n",
        "        plt.scatter(\n",
        "            remain_features[indices_remain, 0],\n",
        "            remain_features[indices_remain, 1],\n",
        "            label=f\"Class {i+1} ({class_name})\",\n",
        "            alpha=0.5,\n",
        "            s=30,\n",
        "            color=colors[i]\n",
        "        )\n",
        "\n",
        "    # Forgetset 데이터 시각화\n",
        "    forget_features = reduced_features[dataset_type == \"Forget\"]\n",
        "    forget_predictions = predictions[dataset_type == \"Forget\"]\n",
        "    for i, class_name in enumerate(classes):\n",
        "        indices_forget = forget_predictions == i\n",
        "        plt.scatter(\n",
        "            forget_features[indices_forget, 0],\n",
        "            forget_features[indices_forget, 1],\n",
        "            alpha=0.6,\n",
        "            s=30,\n",
        "            edgecolor=\"black\",\n",
        "            color=colors[i]\n",
        "        )\n",
        "\n",
        "    plt.title(title, fontsize=20, fontweight=\"bold\")\n",
        "    plt.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5), fontsize=\"small\", markerscale=1.0)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # 시각화 이미지 저장\n",
        "    plt.savefig(save_path, dpi=300)\n",
        "    plt.close()\n",
        "    print(f\"t-SNE visualization saved at {save_path}\")\n",
        "\n",
        "best_weight_path = os.path.join(save_dir, \"Org_Model.pth\")\n",
        "\n",
        "final_model = create_model(num_classes=10).to(device)\n",
        "final_model.load_state_dict(torch.load(best_weight_path))\n",
        "final_model.eval()\n",
        "print(f\"Loaded best weights from {best_weight_path}\")\n",
        "\n",
        "# 각 데이터셋에서 정확도 평가\n",
        "train_forget_acc = evaluate_model(final_model, train_forget_loader, device)\n",
        "train_remain_acc = evaluate_model(final_model, train_remain_loader, device)\n",
        "test_forget_acc = evaluate_model(final_model, test_forget_loader, device)\n",
        "test_remain_acc = evaluate_model(final_model, test_remain_loader, device)\n",
        "\n",
        "# 결과 출력\n",
        "print(f\"Train Remainset Accuracy (others): {train_remain_acc * 100:.2f}%\")\n",
        "print(f\"Train Forgetset Accuracy (deer): {train_forget_acc * 100:.2f}%\")\n",
        "print(f\"Test Remainset Accuracy (others): {test_remain_acc * 100:.2f}%\")\n",
        "print(f\"Test Forgetset Accuracy (deer): {test_forget_acc * 100:.2f}%\")\n",
        "\n",
        "# TSNE 시각화\n",
        "tsne_predictions_path = os.path.join(save_dir, \"tsne_Org_Model.png\")\n",
        "print(\"\\nGenerating TSNE visualization...\")\n",
        "\n",
        "plot_tsne(\n",
        "    final_model,\n",
        "    test_remain_loader,\n",
        "    test_forget_loader,\n",
        "    device,\n",
        "    \"TSNE Visualization(Original Model)\",\n",
        "    classes,\n",
        "    tsne_predictions_path\n",
        ")"
      ],
      "metadata": {
        "id": "mI36vZS0EOgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "boundary unlearning: rapid forgetting of deep networks via shifting the decision boundary(CVPR 2023)\n",
        "\n",
        "Retrain 모델(Dr, 즉 forgetting data를 제외한 데이터세트로 학습한 모델) 학습 및 시각화 코드\n",
        "Train Remainset Accuracy (others): 99.99%\n",
        "Train Forgetset Accuracy (deer): 0.00%\n",
        "Test Remainset Accuracy (others): 83.93%\n",
        "Test Forgetset Accuracy (deer): 0.00%\n",
        "\n",
        "to do : 모듈화\n",
        "\"\"\"\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.models import resnet18\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import random\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "save_dir = \"./Result\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# 데이터셋 분리 함수\n",
        "def split_datasets(dataset, target_class):\n",
        "    forget_indices = [i for i, (_, label) in enumerate(dataset) if label == target_class]\n",
        "    remain_indices = [i for i, (_, label) in enumerate(dataset) if label != target_class]\n",
        "    return Subset(dataset, forget_indices), Subset(dataset, remain_indices)\n",
        "\n",
        "# 삭제 대상 클래스 - deer(4)\n",
        "target_class = 4\n",
        "\n",
        "train_forgetset, train_remainset = split_datasets(train_dataset, target_class)\n",
        "test_forgetset, test_remainset = split_datasets(test_dataset, target_class)\n",
        "\n",
        "train_forget_loader = DataLoader(train_forgetset, batch_size=64, shuffle=True)\n",
        "train_remain_loader = DataLoader(train_remainset, batch_size=64, shuffle=True)\n",
        "test_forget_loader = DataLoader(test_forgetset, batch_size=64, shuffle=False)\n",
        "test_remain_loader = DataLoader(test_remainset, batch_size=64, shuffle=False)\n",
        "\n",
        "# ResNet18 모델\n",
        "def create_model(num_classes=10):\n",
        "    model = resnet18(pretrained=True)\n",
        "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "    return model\n",
        "\n",
        "# 학습 함수\n",
        "def train_model(model, dataloader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    for inputs, labels in dataloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# 평가 함수\n",
        "def evaluate_model(model, dataloader, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return correct / total\n",
        "\n",
        "best_accuracy = 0.0\n",
        "epoch = 50\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "retrain_model = create_model(num_classes=10).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(retrain_model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# 학습\n",
        "for i in range(epoch):\n",
        "    train_model(retrain_model, train_remain_loader, criterion, optimizer, device)\n",
        "    accuracy = evaluate_model(retrain_model, test_remain_loader, device)\n",
        "    print(f\"Epoch {i+1}, Test Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "    # 최고 성능 저장\n",
        "    if accuracy > best_accuracy:\n",
        "        best_accuracy = accuracy\n",
        "\n",
        "        best_weight_path = os.path.join(save_dir, \"retrain_model.pth\")\n",
        "        torch.save(retrain_model.state_dict(), best_weight_path)\n",
        "        print(f\"New best accuracy: {accuracy * 100:.2f}% - Weights saved at {best_weight_path}\")\n",
        "\n",
        "final_model = create_model(num_classes=10).to(device)\n",
        "final_model.load_state_dict(torch.load(best_weight_path))\n",
        "final_model.eval()\n",
        "print(f\"Loaded best weights from {best_weight_path}\")\n",
        "\n",
        "train_forget_acc = evaluate_model(final_model, train_forget_loader, device)\n",
        "train_remain_acc = evaluate_model(final_model, train_remain_loader, device)\n",
        "test_forget_acc = evaluate_model(final_model, test_forget_loader, device)\n",
        "test_remain_acc = evaluate_model(final_model, test_remain_loader, device)\n",
        "\n",
        "print(f\"Train Remainset Accuracy (others): {train_remain_acc * 100:.2f}%\")\n",
        "print(f\"Train Forgetset Accuracy (deer): {train_forget_acc * 100:.2f}%\")\n",
        "print(f\"Test Remainset Accuracy (others): {test_remain_acc * 100:.2f}%\")\n",
        "print(f\"Test Forgetset Accuracy (deer): {test_forget_acc * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "5A95009BrnF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Baseline 만들기\n",
        "2-1. 앞서 학습한 Original 모델을 가지고 논문 baseline으로 설명된 'Random Labels' 기법에 대해 Machine Unlearning을 수행하고 정확도 등을 평가하세요. (Random Labels 기법은 forgetting data에 임의의 라벨을 부여하여 fine-tune합니다.)\n",
        "\n",
        "[2-1 Result]\n",
        "- Train Remainset Accuracy (others): 89.39%\n",
        "- Train Forgetset Accuracy (deer): 8.88%\n",
        "- Test Remainset Accuracy (others): 73.58%\n",
        "- Test Forgetset Accuracy (deer): 6.70%"
      ],
      "metadata": {
        "id": "bKcISx0EKRY1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Selective forgetting of deep networks at a finer level than samples(CoRR 2020)\n",
        "\n",
        "[랜덤 라벨 디스틸레이션(Random Label Distillation, RLD)]\n",
        "특정 입력 데이터가 네트워크에 무작위 라벨을 학습하도록 강제하여 기존 학습된 정보를 \"망각\" 시킴\n",
        "\n",
        "[학습 목표]\n",
        "Df(잊어야할 데이터)에 대한 성능은 떨어뜨리고, Dr(나머지 데이터)의 성능은 유지하는 것이 목표\n",
        "이를 위해 2가지의 손실 함수를 결합하여 사용\n",
        "\n",
        "### 망각 손실(Lf)\n",
        "- Df 데이터에 대한 성능을 낮추기 위해 사용\n",
        "- 랜덤 라벨 디스틸레이션(Random Label Distillation, RLD)을 사용하여 Df를 망각 시킴\n",
        "- $ L_{\\text{RLD}}(f_\\theta, x_f) = L_{\\text{cls}}(f_\\theta(x_f), u) $\n",
        "  - $f_\\theta(x_f)$ : 모델이 xf에 대해 출력한 로짓 값\n",
        "  - u : xf에 대해 무작위로 선택된 클래스\n",
        "  - $L_{\\text{cls}}$ : Softmax Cross-Entropy Loss\n",
        "  - 즉, xf를 원래의 정답 라벨이 아닌 랜덤 라벨로 학습시킴으로써, 해당 데이터에 대한 기존 학습 내용을 잊게 한다.\n",
        "\n",
        "### 기억 손실(R)\n",
        "- Dr 데이터에 대한 성능을 유지하기 위해 사용\n",
        "- Elastic Weight Consolidation(EWC) 방식을 사용하여 모델이 기존 데이터의 중요한 특징을 유지하도록 정규화\n",
        "- $ R(f_\\theta, f_{\\theta_{\\text{old}}}) = (\\theta - \\theta_{\\text{old}})^T F(\\theta_{\\text{old}})(\\theta - \\theta_{\\text{old}}) $\n",
        "  - $\\theta$ : 현재 학습 중인 모델의 파라미터 벡터\n",
        "  - $\\theta_{\\text{old}}$ : 과거 모델(original 모델)의 파라미터 벡터\n",
        "  - $F(\\theta_{\\text{old}})$ : Fisher 정보 행렬. 각 파라미터의 중요도를 나타냄\n",
        "-  Fisher 정보 행렬($F(\\theta)_{ii}$)\n",
        "  - 파라미터 𝜃에 대한 손실 함수의 민감도(각 파라미터가 손실에 얼마나 중요한지에 대한 정보)\n",
        "  - $F(\\theta_{\\text{old}})_{ii} = |D|^{-1} \\sum_{(x, l) \\in D} \\left[ \\frac{\\partial L_{\\text{cls}}(f_\\theta(x), l)}{\\partial \\theta_i} \\right]^2$\n",
        "  - 모든 파라미터 $\\theta_i$에 대해 손실함수 $L_{\\text{cls}}$의 편미분의 제곱의 평균의 대각 성분\n",
        "- $ \\frac{\\partial R}{\\partial \\theta_i} = 2 \\cdot F(\\theta_{\\text{old}})_{ii} \\cdot (\\theta_i - \\theta_{\\text{old}, i})$\n",
        "  - EWC 손실 항에 대해 $\\theta_i$에 대한 기울기\n",
        "  - 즉, Fisher 정보가 클수록 기울기의 크기가 커진다.\n",
        "  - 경사하강법에서 큰 기울기는 파라미터 업데이트를 강하게 유도하여 손실을 빠르게 줄인다.\n",
        "  - 따라서 중요한 파라미터(Fisher 정보가 큰)는 원래 값에 머무르려는 경향이 강해지고, 큰 변화가 제한된다.\n",
        "- <확인해보기> 이차형식(Quadratic Forms)...????\n",
        "\n",
        "### 최종 손실 함수\n",
        "- $L = L_f(f_\\theta, D_f) + \\lambda_{\\text{KL}} \\cdot R(f_\\theta, f_{\\theta_{\\text{old}}})$\n",
        "  - $\\lambda_{\\text{KL}}$ : R에 대한 가중치(0 이상, 고정값)\n",
        "\n"
      ],
      "metadata": {
        "id": "q5f-NQVhaL9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "boundary unlearning: rapid forgetting of deep networks via shifting the decision boundary(CVPR 2023)\n",
        "\n",
        "Random Labels 모델(랜덤으로 라벨링한 forgetting data를 사용해 original 모델을 파인튜닝) 학습 및 시각화 코드\n",
        "\n",
        "Train Remainset Accuracy (others): 89.39%\n",
        "Train Forgetset Accuracy (deer): 8.88%\n",
        "Test Remainset Accuracy (others): 73.58%\n",
        "Test Forgetset Accuracy (deer): 6.70%\n",
        "\n",
        "to do :\n",
        "- 모듈화\n",
        "- ASR 추가\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "Selective forgetting of deep networks at a finer level than samples(CoRR 2020)\n",
        "\n",
        "[랜덤 라벨 디스틸레이션(Random Label Distillation, RLD)]\n",
        "특정 입력 데이터가 네트워크에 무작위 라벨을 학습하도록 강제하여 기존 학습된 정보를 \"망각\" 시킴\n",
        "\n",
        "[학습 목표]\n",
        "Df(잊어야할 데이터)에 대한 성능은 떨어뜨리고, Dr(나머지 데이터)의 성능은 유지하는 것이 목표\n",
        "이를 위해 2가지의 손실 함수를 결합하여 사용\n",
        "\n",
        "1. 망각 손실(Lf)\n",
        "Df 데이터에 대한 성능을 낮추기 위해 사용\n",
        "랜덤 라벨 디스틸레이션(Random Label Distillation, RLD)을 사용하여 Df를 망각 시킴\n",
        "\n",
        "2. 기억 손실(R)\n",
        "Dr 데이터에 대한 성능을 유지하기 위해 사용\n",
        "Elastic Weight Consolidation(EWC) 방식을 사용하여 모델이 기존 데이터의 중요한 특징을 유지하도록 정규화\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.models import resnet18\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import random\n",
        "import numpy as np\n",
        "import os\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# 랜덤 시드 고정\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "save_dir = \"./Result\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# 데이터셋 분리 함수\n",
        "def split_datasets(dataset, target_class):\n",
        "    forget_indices = [i for i, (_, label) in enumerate(dataset) if label == target_class]\n",
        "    remain_indices = [i for i, (_, label) in enumerate(dataset) if label != target_class]\n",
        "    return Subset(dataset, forget_indices), Subset(dataset, remain_indices)\n",
        "\n",
        "target_class = 4  # deer\n",
        "\n",
        "train_forgetset, train_remainset = split_datasets(train_dataset, target_class)\n",
        "test_forgetset, test_remainset = split_datasets(test_dataset, target_class)\n",
        "\n",
        "train_forget_loader = DataLoader(train_forgetset, batch_size=64, shuffle=True)\n",
        "train_remain_loader = DataLoader(train_remainset, batch_size=64, shuffle=True)\n",
        "test_forget_loader = DataLoader(test_forgetset, batch_size=64, shuffle=False)\n",
        "test_remain_loader = DataLoader(test_remainset, batch_size=64, shuffle=False)\n",
        "\n",
        "def create_model(num_classes=10):\n",
        "    model = resnet18(pretrained=True)\n",
        "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "    return model\n",
        "\n",
        "# 랜덤 라벨 생성 함수\n",
        "def generate_random_labels(labels, num_classes):\n",
        "    random_labels = torch.randint(0, num_classes, labels.size(), device=labels.device)\n",
        "    while (random_labels == labels).any():\n",
        "        random_labels = torch.randint(0, num_classes, labels.size(), device=labels.device)\n",
        "    return random_labels\n",
        "\n",
        "# Random Label Distillation(RLD) Loss : CrossEntropyLoss 사용\n",
        "# 망각 손실(Lf) 참고\n",
        "def random_label_distillation_loss(outputs, random_labels):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    return criterion(outputs, random_labels)\n",
        "\n",
        "# Elastic Weight Consolidation (EWC) Loss\n",
        "# 기억 손실(R) 참고\n",
        "def ewc_loss(model, fisher_matrix, old_weights, lambda_ewc):\n",
        "    ewc_loss_value = 0\n",
        "    for name, param in model.named_parameters():\n",
        "        if name in fisher_matrix:\n",
        "            fisher = fisher_matrix[name]   # fisher 정보(파라미터 중요도)\n",
        "            old_weight = old_weights[name] # original 모델의 파라미터 값\n",
        "            # (현재 파라미터 - 과거 파라미터)^2에 Fisher 정보로 가중치 부여 후 합산\n",
        "            ewc_loss_value += (fisher * (param - old_weight).pow(2)).sum()\n",
        "    # EWC 손실에 가중치 부여\n",
        "    return lambda_ewc * ewc_loss_value\n",
        "\n",
        "# Fisher 정보 계산 함수\n",
        "# original 모델로부터 파라미터 중요도 계산\n",
        "def calculate_fisher_information(model, dataloader, device):\n",
        "    # fisher행렬 초기화(모델의 각 파라미터에 대해 0으로 초기화)\n",
        "    fisher_matrix = {name: torch.zeros_like(param) for name, param in model.named_parameters() if param.requires_grad}\n",
        "    model.eval()\n",
        "\n",
        "    for inputs, labels in dataloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        model.zero_grad()\n",
        "        # fθ(x)\n",
        "        outputs = model(inputs)\n",
        "        # Lcls(fθ(x),l)\n",
        "        loss = nn.CrossEntropyLoss()(outputs, labels)\n",
        "        # ∂Lcls(fθ(x),l) / ∂θi\n",
        "        loss.backward()\n",
        "\n",
        "        # 최종 fisher 정보 행렬\n",
        "        # 손실 함수의 기울기 제곱의 평균으로 정의\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.requires_grad and param.grad is not None:\n",
        "                fisher_matrix[name] += param.grad.pow(2) / len(dataloader)\n",
        "\n",
        "    return fisher_matrix\n",
        "\n",
        "# 학습 함수\n",
        "def train_model(model, dataloader, optimizer, fisher_matrix, old_weights, lambda_ewc, device):\n",
        "    model.train()\n",
        "    for inputs, labels in dataloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # 랜덤 라벨 생성\n",
        "        random_labels = generate_random_labels(labels, len(classes))\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # 망각 손실 (RLD)\n",
        "        rld_loss = random_label_distillation_loss(outputs, random_labels)\n",
        "\n",
        "        # 기억 손실 (EWC)\n",
        "        ewc_loss_value = ewc_loss(model, fisher_matrix, old_weights, lambda_ewc)\n",
        "\n",
        "        # 총 손실\n",
        "        loss = rld_loss + ewc_loss_value\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "# 평가 함수\n",
        "def evaluate_model(model, dataloader, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return correct / total\n",
        "\n",
        "# 모델 초기화 및 학습\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "Random_Labels_Model = create_model(num_classes=len(classes)).to(device)\n",
        "original_model = create_model(num_classes=len(classes)).to(device)\n",
        "\n",
        "original_weights_path = \"./Result/Org_Model.pth\"\n",
        "original_model.load_state_dict(torch.load(original_weights_path))\n",
        "print(f\"Loaded original model weights from {original_weights_path}\")\n",
        "\n",
        "Random_Labels_Model.load_state_dict(copy.deepcopy(original_model.state_dict()))\n",
        "\n",
        "# original_model 가중치\n",
        "old_weights = {name: param.clone().detach() for name, param in original_model.named_parameters()}\n",
        "# 전체 데이터에 대해 Fisher 정보 행렬 계산\n",
        "fisher_matrix = calculate_fisher_information(original_model, train_loader, device)\n",
        "\n",
        "# We set λKL = 10^5, lr = 10^−5 throughout experiments.\n",
        "optimizer = optim.SGD(Random_Labels_Model.parameters(), lr=1e-5)\n",
        "lambda_ewc = 1e5\n",
        "best_tradeoff_score = -float('inf')\n",
        "\n",
        "for epoch in range(10):\n",
        "    print(f\"Epoch {epoch + 1}/10\")\n",
        "    train_model(Random_Labels_Model, train_forget_loader, optimizer, fisher_matrix, old_weights, lambda_ewc, device)\n",
        "\n",
        "    #train_remain_acc = evaluate_model(Random_Labels_Model, train_remain_loader, device)\n",
        "    test_remain_acc = evaluate_model(Random_Labels_Model, test_remain_loader, device)\n",
        "    #train_forget_acc = evaluate_model(Random_Labels_Model, train_forget_loader, device)\n",
        "    test_forget_acc = evaluate_model(Random_Labels_Model, test_forget_loader, device)\n",
        "\n",
        "    # print(f\"Train Remainset Accuracy: {train_remain_acc * 100:.2f}%\")\n",
        "    # print(f\"Train Forgetset Accuracy: {train_forget_acc * 100:.2f}%\")\n",
        "    # print(f\"Test Remainset Accuracy: {test_remain_acc * 100:.2f}%\")\n",
        "    # print(f\"Test Forgetset Accuracy: {test_forget_acc * 100:.2f}%\")\n",
        "\n",
        "    tradeoff_score = test_remain_acc - test_forget_acc\n",
        "\n",
        "    if tradeoff_score > best_tradeoff_score:\n",
        "        best_tradeoff_score = tradeoff_score\n",
        "        best_weight_path = os.path.join(save_dir, \"Random_Labels_Model.pth\")\n",
        "        torch.save(Random_Labels_Model.state_dict(), best_weight_path)\n",
        "        print(f\"New best trade-off score: {tradeoff_score:.4f} - Model saved to {best_weight_path}\")\n",
        "\n",
        "print(\"Training complete.\")\n",
        "\n",
        "final_model = create_model(num_classes=10).to(device)\n",
        "final_model.load_state_dict(torch.load(best_weight_path))\n",
        "final_model.eval()\n",
        "print(f\"Loaded best weights from {best_weight_path}\")\n",
        "\n",
        "train_forget_acc = evaluate_model(final_model, train_forget_loader, device)\n",
        "train_remain_acc = evaluate_model(final_model, train_remain_loader, device)\n",
        "test_forget_acc = evaluate_model(final_model, test_forget_loader, device)\n",
        "test_remain_acc = evaluate_model(final_model, test_remain_loader, device)\n",
        "\n",
        "# 결과 출력\n",
        "print(f\"Train Remainset Accuracy (others): {train_remain_acc * 100:.2f}%\")\n",
        "print(f\"Train Forgetset Accuracy (deer): {train_forget_acc * 100:.2f}%\")\n",
        "print(f\"Test Remainset Accuracy (others): {test_remain_acc * 100:.2f}%\")\n",
        "print(f\"Test Forgetset Accuracy (deer): {test_forget_acc * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "aWY-jLegEPy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. 논문의 아이디어 구현하기\n",
        "3-1. 논문의 메인 아이디어 중 하나인 'Boundary Shrink'를 구현하고 각 데이터에 대한 정확도 등을 평가하세요. 이때 adversarial attack 기법인 PGD attack를 직접 구현해보세요 (어려우시면 다른데서 찾아오셔도 됩니다.)\n",
        "\n",
        "3-2. Retrain, Random Labels, Boundary Shrink 세 기법의 결과를 서로 비교하고 평가하세요.\n",
        "\n",
        "[3-1 Result]\n",
        "- Train Remainset Accuracy (others): 94.02%\n",
        "- Train Forgetset Accuracy (deer): 3.22%\n",
        "- Test Remainset Accuracy (others): 77.32%\n",
        "- Test Forgetset Accuracy (deer): 2.50%\n",
        "\n",
        "    <img src='https://drive.google.com/uc?id=1NL9QlqVnLxRq0cpxJz81Z6dLjfkf8b6y' width='450' height='450' />\n",
        "\n",
        "[3-2 Result]\n",
        "- Retrain 모델\n",
        "  - Forgetset의 Accuracy가 0%로, 삭제된 데이터에 대한 정보가 완전히 제거됨. 하지만 처음부터 다시 학습해야 하므로, 연산 비용과 시간이 매우 큼.\n",
        "- Random Labels\n",
        "  - Boundary Shrink보다 적은 계산 비용으로 Forgetset의 Accuracy를 낮출 수 있다. 하지만, Boundary Shrink에 비해 성능이 낮다.\n",
        "- Boundary Shrink\n",
        "  - Forgetset Accuracy가 2.50%로, Random Labels보다 강력한 Privacy Guarantee를 제공한다.\n",
        "  - 또한  Remaining Class의 성능 손상(Train Remainset Accuracy 94.02%)을 최소화 하였다.\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "  | **Metric**                          | **Original** | **Retrain** | **Random Labels** | **Boundary Shrink** |\n",
        "|-------------------------------------|--------------|-------------|--------------------|----------------------|\n",
        "| **Train Remainset Accuracy (others)** | 99.99%       | 99.99%      | 89.39%            | 94.02%              |\n",
        "| **Train Forgetset Accuracy (deer)**  | 100.00%      | 0.00%       | 8.88%             | 3.22%               |\n",
        "| **Test Remainset Accuracy (others)** | 83.08%       | 83.93%      | 73.58%            | 77.32%              |\n",
        "| **Test Forgetset Accuracy (deer)**   | 82.50%       | 0.00%       | 6.70%             | 2.50%               |\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1Q31HKVlS-XTPBtHbs6orWKHlry7xSh6h' width='1000' height='450' />\n"
      ],
      "metadata": {
        "id": "szXxDebxKRo8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "boundary unlearning: rapid forgetting of deep networks via shifting the decision boundary(CVPR 2023)\n",
        "\n",
        "Boundary Shrink 모델 학습 및 시각화(https://www.dropbox.com/scl/fi/j3hgtrvp1vjptk9qz5ck6/Boundary-Unlearning-Code.zip?rlkey=h32gro8ysi4umtolzmi54gbdo&e=1&dl=0)\n",
        "\n",
        "Train Remainset Accuracy (others): 94.02%\n",
        "Train Forgetset Accuracy (deer): 3.22%\n",
        "Test Remainset Accuracy (others): 77.32%\n",
        "Test Forgetset Accuracy (deer): 2.50%\n",
        "\n",
        "to do :\n",
        "- 모듈화\n",
        "- ASR 추가\n",
        "\"\"\"\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.models import resnet18\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import random\n",
        "import numpy as np\n",
        "import os\n",
        "import copy\n",
        "from tqdm import tqdm\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.distributions as distributions\n",
        "import torch\n",
        "from torch import nn\n",
        "from tqdm import tqdm\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=False, transform=transform)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, download=False, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "def split_datasets(dataset, target_class):\n",
        "    forget_indices = [i for i, (_, label) in enumerate(dataset) if label == target_class]\n",
        "    remain_indices = [i for i, (_, label) in enumerate(dataset) if label != target_class]\n",
        "    return Subset(dataset, forget_indices), Subset(dataset, remain_indices)\n",
        "\n",
        "target_class = 4\n",
        "train_forgetset, train_remainset = split_datasets(train_dataset, target_class)\n",
        "test_forgetset, test_remainset = split_datasets(test_dataset, target_class)\n",
        "\n",
        "train_forget_loader = DataLoader(train_forgetset, batch_size=64, shuffle=True)\n",
        "train_remain_loader = DataLoader(train_remainset, batch_size=64, shuffle=True)\n",
        "test_forget_loader = DataLoader(test_forgetset, batch_size=64, shuffle=False)\n",
        "test_remain_loader = DataLoader(test_remainset, batch_size=64, shuffle=False)\n",
        "\n",
        "def create_model(num_classes=10):\n",
        "    model = resnet18(pretrained=False)\n",
        "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "    return model\n",
        "\n",
        "\"\"\"\n",
        "adversarial attack이란? : perturbation(사람의 눈으로는 구별 불가능하지만, 모델의 예측에 영향을 주도록 하는 노이즈)를 추가하여 모델의 오분류를 유도하는 공격 기법\n",
        "대표적인 기법으로는 FGSM과 PGD가 존재한다.\n",
        "\n",
        "1. FGSM(Fast Gradient Sign Method)\n",
        "    Explaining and Harnessing Adversarial Examples(ICLR 2015)\n",
        "    오분류를 일으킬 수 있는 최적의 perturbation(노이즈, 델타)를 찾는 방법\n",
        "    - 손실함수 L의 입력 x에 대한 gradient를 계산.\n",
        "    - sign을 취하여 부호(방향)만을 추출\n",
        "    - 일정한 값(엡실론)을 추가\n",
        "    한번의 기울기 계산만 수행하므로 빠르고 계산 비용이 낮다.\n",
        "\n",
        "2. PGD(Projected Gradient Descent)\n",
        "    Towards Deep Learning Models Resistant to Adversarial Attacks(ICLR 2018)\n",
        "    FGSM을 반복 수행하여 gradient를 업데이트\n",
        "    각 과정에서  step size(=lr) 지정\n",
        "    -> 더 강력한 adversarial sample을 생성 가능하다.\n",
        "    각 과정에서 projection을 통해 perturbation(델타)을 일정 범위(L-infinity norm)내로 제한한다.\n",
        "\"\"\"\n",
        "class LinfPGD:\n",
        "    def __init__(self, model=None, bound=None, step=None, iters=None, norm=False, random_start=False, device=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            model : 공격 대상 모델 - test 모델\n",
        "            bound (float): 허용 범위 (L-infinity 기준 epsilon 값) - 0.1\n",
        "            step (float): 한 번의 업데이트에서 변경할 크기 (step size) - 2 / 255\n",
        "            iters (int): 적대적 샘플 생성을 반복할 횟수 - 5\n",
        "            norm (bool): 입력 데이터를 정규화할지 여부 - True\n",
        "            random_start (bool): 초기 샘플에 무작위 변동을 추가할지 여부 - True\n",
        "            device\n",
        "        \"\"\"\n",
        "        self.model = model\n",
        "        self.bound = bound\n",
        "        self.step = step\n",
        "        self.iter = iters\n",
        "        self.norm = norm\n",
        "        if self.norm:\n",
        "            # CIFAR10 데이터셋 기준 정규화 평균 및 표준편차\n",
        "            self.mean = (0.4914, 0.4822, 0.2265)\n",
        "            self.std = (0.2023, 0.1994, 0.2010)\n",
        "        self.rand = random_start\n",
        "        self.device = device\n",
        "        # CrossEntropyLoss 사용\n",
        "        self.criterion = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "    def perturb(self, x, y, model=None, bound=None, step=None, iters=None, x_nat=None, device=None):\n",
        "        \"\"\"\n",
        "        PGD(Projected Gradient Descent) attack을 수행하여 적대적 샘플 생성\n",
        "\n",
        "        Args:\n",
        "            x : 원본 입력 데이터\n",
        "            y : 원본 입력 데이터의 정답 라벨\n",
        "            model : 공격 대상 모델 - test 모델\n",
        "            bound (float): 허용 범위 (L-infinity 기준 epsilon 값) - 0.1\n",
        "            step (float): 한 번의 업데이트에서 변경할 크기 (step size) - 2 / 255\n",
        "            iters (int): 적대적 샘플 생성을 반복할 횟수 - 5\n",
        "            x_nat (torch.Tensor): 정규화되지 않은 원본 입력 데이터 - None\n",
        "            device\n",
        "        \"\"\"\n",
        "        criterion = self.criterion   # CrossEntropyLoss\n",
        "        model = model or self.model\n",
        "        bound = bound or self.bound\n",
        "        step = step or self.step\n",
        "        iters = iters or self.iter\n",
        "        device = device or self.device\n",
        "\n",
        "        # 모델 그레디언트 초기화\n",
        "        model.zero_grad()\n",
        "\n",
        "        # 정규화되지 않은 원본 데이터를 생성 (기본 설정).\n",
        "        # torch.detach().clone() : 그래디언트 계산 그래프에서 분리 후 복사하여 새로운 메모리 공간에 저장\n",
        "        if x_nat is None:\n",
        "            x_nat = self.inverse_normalize(x.detach().clone().to(device))\n",
        "        else:\n",
        "            x_nat = self.inverse_normalize(x_nat.detach().clone().to(device))\n",
        "\n",
        "        # 적대적 샘플 초기화\n",
        "        x_adv = x.detach().clone().requires_grad_(True).to(device)\n",
        "\n",
        "        # 적대적 샘플에 노이즈 추가한 상태로 시작\n",
        "        if self.rand:\n",
        "            # 허용 범위 내에서 랜덤한 노이즈를 생성\n",
        "            rand_perturb_dist = distributions.uniform.Uniform(-bound, bound)\n",
        "            rand_perturb = rand_perturb_dist.sample(sample_shape=x_adv.shape).to(device)\n",
        "            # 생성한 노이즈 추가 및 범위 제한\n",
        "            x_adv = self.clamper(self.inverse_normalize(x_adv) + rand_perturb, self.inverse_normalize(x_nat),\n",
        "                                 bound=bound, inverse_normalized=True)\n",
        "            # 노이즈 추가한 초기 x_adv 정규화 및 이산화\n",
        "            x_adv = self.normalize(self.discretize(x_adv)).detach().clone().requires_grad_(True)\n",
        "\n",
        "        # PGD attack 반복 -> 최적의 적대적 샘플 반환\n",
        "        for i in range(iters):\n",
        "            # 현재 적대적 샘플에 대한 모델(original 모델) 출력\n",
        "            adv_pred = model(x_adv)\n",
        "            # loss 계산. 모델 예측값과 실제 정답 간의 손실 계산\n",
        "            loss = criterion(adv_pred, y)\n",
        "            # 손실함수의 그래디언트 계산 - 수식(2)\n",
        "            loss.backward()\n",
        "            # 그래디언트의 부호 계산 - 수식(2)\n",
        "            grad_sign = x_adv.grad.data.detach().sign()\n",
        "            # x_adv를 업데이트: x_adv에 step size만큼 perturbation 추가 - 수식(2)\n",
        "            x_adv = self.inverse_normalize(x_adv) + grad_sign * step\n",
        "            # 범위 제한\n",
        "            x_adv = self.clamper(x_adv, x_nat, bound=bound, inverse_normalized=True)\n",
        "            model.zero_grad()\n",
        "\n",
        "        # 최종적으로 적대적 샘플 반환(노이즈가 추가된 x)\n",
        "        return x_adv.detach().to(device)\n",
        "\n",
        "    # 입력 데이터 정규화\n",
        "    def normalize(self, x):\n",
        "        # x shape : (batch_size, channel, height, width)\n",
        "        # norm이 True일 경우에는 정규화 후 반환\n",
        "        # norm이 False일 경우에는 그대로 반환\n",
        "        if self.norm:\n",
        "            y = x.clone().to(x.device)\n",
        "            # 각 체널별로 정규화 (x - 평균)/표준편차\n",
        "            y[:, 0, :, :] = (y[:, 0, :, :] - self.mean[0]) / self.std[0]  # R체널\n",
        "            y[:, 1, :, :] = (y[:, 1, :, :] - self.mean[1]) / self.std[1]  # G체널\n",
        "            y[:, 2, :, :] = (y[:, 2, :, :] - self.mean[2]) / self.std[2]  # B체널\n",
        "            return y\n",
        "        return x\n",
        "\n",
        "    # 입력 데이터 역정규화\n",
        "    def inverse_normalize(self, x):\n",
        "        if self.norm:\n",
        "            y = x.clone().to(x.device)\n",
        "            y[:, 0, :, :] = y[:, 0, :, :] * self.std[0] + self.mean[0]\n",
        "            y[:, 1, :, :] = y[:, 1, :, :] * self.std[1] + self.mean[1]\n",
        "            y[:, 2, :, :] = y[:, 2, :, :] * self.std[2] + self.mean[2]\n",
        "            return y\n",
        "        return x\n",
        "\n",
        "    # 데이터 이산화 -> 계산 이득?\n",
        "    def discretize(self, x):\n",
        "        return torch.round(x * 255) / 255\n",
        "\n",
        "    # 적대적 샘플(x_adv)이 원본 샘플(x_nat)의 허용 범위(bound)를 넘지 않도록 제한(clamp)하는 함수\n",
        "    # torch.clamp(x, a, b) : x의 값을 a, b 범위 안으로 조정해주는 함수\n",
        "    def clamper(self, x_adv, x_nat, bound=None, inverse_normalized=False):\n",
        "        # 역정규화 안되어 있으면 역정규화 진행\n",
        "        if not inverse_normalized:\n",
        "            x_adv = self.inverse_normalize(x_adv)\n",
        "            x_nat = self.inverse_normalize(x_nat)\n",
        "\n",
        "        # 픽셀 값 차이를 bound로 제한\n",
        "        clamp_delta = torch.clamp(x_adv - x_nat, -bound, bound)\n",
        "\n",
        "        # 노이즈 더해주기\n",
        "        x_adv = x_nat + clamp_delta\n",
        "        # 범위 제한(0~1)사이로\n",
        "        x_adv = torch.clamp(x_adv, 0., 1.)\n",
        "        # 이산화(discretize) 및 정규화(normalize) 후 반환, 이후 추가 그래디언트 계산 가능하도록 requires_grad 설정\n",
        "        return self.normalize(self.discretize(x_adv)).clone().detach().requires_grad_(True)\n",
        "\n",
        "\n",
        "def inf_generator(iterable):\n",
        "    iterator = iterable.__iter__()\n",
        "    while True:\n",
        "        try:\n",
        "            yield iterator.__next__()\n",
        "        except StopIteration:\n",
        "            iterator = iterable.__iter__()\n",
        "\n",
        "###################################################################################################################################################\n",
        "\n",
        "# boundary_shrink\n",
        "def boundary_shrink(ori_model, train_forget_loader, dt, dv, test_loader, device, evaluate,\n",
        "                    bound=0.1, step=2 / 255, iter=5, poison_epoch=10, forget_class=0, path='./'):\n",
        "\n",
        "    # 정규화, 무작위 시작\n",
        "    norm = True\n",
        "    random_start = True\n",
        "\n",
        "    # test_model : 적대적 샘플 생성에 사용\n",
        "    # unlearn_model : 학습(unlearning)에 사용\n",
        "    test_model = copy.deepcopy(ori_model).to(device)\n",
        "    unlearn_model = copy.deepcopy(ori_model).to(device)\n",
        "\n",
        "    # LinfPGD 인스턴스 생성(적대적 샘플 생성을 위한)\n",
        "    adv = LinfPGD(test_model, bound, step, iter, norm, random_start, device)\n",
        "\n",
        "    # loss / 옵티마이저 설정\n",
        "    # 논문 : For the fine-tune process in Boundary Unlearning we use a learning rate of 10−5 for 10 epochs.\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(unlearn_model.parameters(), lr=1e-5, momentum=0.9)\n",
        "\n",
        "    # num_hits = 0\n",
        "    # num_sum = 0\n",
        "    best_tradeoff_score = -float('inf')\n",
        "    best_weight_path = os.path.join(path, \"shrink_model.pth\")\n",
        "\n",
        "    # boundary shrink 학습 과정\n",
        "    for epoch in range(poison_epoch):\n",
        "        print(f\"Epoch {epoch + 1}/{poison_epoch}\")\n",
        "\n",
        "        for x, y in tqdm(train_forget_loader, desc=f\"Epoch {epoch + 1} Batches\"):\n",
        "            x, y = x.to(device), y.to(device)\n",
        "\n",
        "            # test모델(적대적 샘플 생성을 위한 모델)을 사용해 적대적 샘플을 생성\n",
        "            # 적대적 샘플 : 노이즈 추가된 x\n",
        "            test_model.eval()\n",
        "            x_adv = adv.perturb(x, y, model=test_model, device=device)\n",
        "\n",
        "            # 적대적 샘플에 대한 예측값 출력 및 예측 라벨 계산\n",
        "            adv_logits = test_model(x_adv)\n",
        "            pred_label = torch.argmax(adv_logits, dim=1)\n",
        "\n",
        "            # num_hits += (y != pred_label).float().sum()\n",
        "            # num_sum += y.shape[0]\n",
        "\n",
        "            # unlearn모델 학습\n",
        "            unlearn_model.train()\n",
        "            optimizer.zero_grad()\n",
        "            # unlearn모델에 적대적 샘플을 넣어 모델의 예측 출력\n",
        "            ori_logits = unlearn_model(x)\n",
        "            # loss 계산 - 모델의 예측값과 적대적 샘플의 라벨(바뀐 라벨) 손실 계산\n",
        "            loss = criterion(ori_logits, pred_label)\n",
        "            # 손실함수 그래디언트 계산 및 업데이트\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        test_remain_acc = evaluate_model(unlearn_model, test_remain_loader, device)\n",
        "        test_forget_acc = evaluate_model(unlearn_model, test_forget_loader, device)\n",
        "\n",
        "        print(f\"Test Remainset Accuracy: {test_remain_acc * 100:.2f}%\")\n",
        "        print(f\"Test Forgetset Accuracy: {test_forget_acc * 100:.2f}%\")\n",
        "        tradeoff_score = test_remain_acc - test_forget_acc\n",
        "\n",
        "        if tradeoff_score > best_tradeoff_score:\n",
        "            best_tradeoff_score = tradeoff_score\n",
        "            torch.save(unlearn_model.state_dict(), best_weight_path)\n",
        "            print(f\"New best trade-off score: {tradeoff_score:.4f} - Model saved to {best_weight_path}\")\n",
        "\n",
        "    # asr = (num_hits / num_sum).float()\n",
        "    # print('Attack Success Ratio (ASR):', asr)\n",
        "\n",
        "    return unlearn_model\n",
        "\n",
        "###################################################################################################################################################\n",
        "\n",
        "\n",
        "# 정확도 평가 함수\n",
        "def evaluate_model(model, dataloader, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return correct / total\n",
        "\n",
        "# 모델 생성 및 로드\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "ori_model = create_model(num_classes=10).to(device)\n",
        "original_weights_path = \"./Result/Org_Model.pth\"\n",
        "ori_model.load_state_dict(torch.load(original_weights_path))\n",
        "print(f\"Original model loaded from {original_weights_path}\")\n",
        "\n",
        "save_dir = \"./Result\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "evaluation = ''\n",
        "\n",
        "unlearn_model = boundary_shrink(ori_model, train_forget_loader, train_dataset, test_dataset,\n",
        "                                                    test_loader, device, evaluation,\n",
        "                                                    forget_class=target_class, path=save_dir)\n",
        "\n",
        "# 디바이스 설정 및 모델 로드\n",
        "best_weight_path = os.path.join(save_dir, \"shrink_model.pth\")\n",
        "final_model = create_model(num_classes=10).to(device)\n",
        "final_model.load_state_dict(torch.load(best_weight_path))\n",
        "\n",
        "# 각 데이터셋에서 정확도 평가\n",
        "train_forget_acc = evaluate_model(final_model, train_forget_loader, device)\n",
        "train_remain_acc = evaluate_model(final_model, train_remain_loader, device)\n",
        "test_forget_acc = evaluate_model(final_model, test_forget_loader, device)\n",
        "test_remain_acc = evaluate_model(final_model, test_remain_loader, device)\n",
        "\n",
        "# 결과 출력\n",
        "print(f\"Train Remainset Accuracy (others): {train_remain_acc * 100:.2f}%\")\n",
        "print(f\"Train Forgetset Accuracy (deer): {train_forget_acc * 100:.2f}%\")\n",
        "print(f\"Test Remainset Accuracy (others): {test_remain_acc * 100:.2f}%\")\n",
        "print(f\"Test Forgetset Accuracy (deer): {test_forget_acc * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "iVo6tLkBEQYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 4. 평가\n",
        "4-1. 논문과 실험의 주요 contribution, weakness, 개선할 점, 구현 시 느낀점 등, 본인의 생각을 자유롭게 적어주세요\n",
        "\n",
        "1. 주요 Contribution\n",
        "  - 결정 경계를 이동시켜 특정 클래스 정보를 제거하는 최초의 unlearning 기법을 제안함\n",
        "  - Utility와 Privacy 보장을 동시에 만족하면서도 빠르고 효율적인 망각 성능을 실험적으로 입증함\n",
        "\n",
        "2. Weakness\n",
        "  - Boundary Shrink는 적대적 샘플 생성 과정에서 높은 computational cost를 요구하며, 대규모 데이터세트나 복잡한 모델에서는 성능 저하 가능성이 있다고 생각한다.\n",
        "\n",
        "3. 개선할 점\n",
        "  - 대규모 데이터셋과 복잡한 모델에 대해서도 일관된 성능을 유지하는지 추가 검증이 필요하다고 생각한다.\n",
        "\n",
        "4. 느낀점\n",
        "  - 논문에서는 Remaining Class(Dr)의 Accuracy가 99%, 98% 수준으로 유지된다고 되어 있으나, 실험 결과는 90%, 94%로 다소 낮게 나왔다. 이는 실험 환경이나 구현 세부사항, 혹은 데이터 전처리 과정에서의 차이 때문일 가능성이 있어 추가적인 확인이 필요해 보인다.\n",
        "  - 논문에서 제안된 수식(Random Labels의 망각 손실 함수와 Boundary Shrink의 PGD 공격)을 이해하고 구현하는 데 어려움을 느꼈다. 특히, 제안된 방법들이 개념적으로 이해는 되었으나, 이를 실제 코드로 구현하는 데 시간이 걸렸다.\n",
        "  - 결론적으로, 논문을 깊이 이해하고 구현하는 과정에서 수학적 직관과 코딩 역량을 강화해야 한다는 필요성을 느꼈으며, 이를 위해 체계적인 학습과 실습이 필요하다고 느꼈다."
      ],
      "metadata": {
        "id": "eCcbem5vKR4p"
      }
    }
  ]
}